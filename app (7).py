# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JlCgfpyODjfTTE1-zVD5rnk3XPk_nq9b
"""

import streamlit as st
import numpy as np
import cv2
import torch
import torch.nn as nn
from PIL import Image
import os

# -------------------------
# Streamlit App: Vegetation Segmentation (PyTorch U-Net)
# Save this file as app.py and place your weights file
# `desert_agri_unet_weights.pth` in the same repo or upload it via the UI.
# Suggested requirements (put in requirements.txt):
# streamlit
# torch
# torchvision
# opencv-python
# numpy
# pillow
# matplotlib
# tqdm
# -------------------------

IMAGE_SIZE = (128, 128)
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# -------------------------
# Model definition (same architecture as training notebook)
# -------------------------
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.ReLU(inplace=True),
        )

    def forward(self, x):
        return self.conv(x)


class UNet(nn.Module):
    def __init__(self):
        super().__init__()

        self.down1 = DoubleConv(3, 16)
        self.pool1 = nn.MaxPool2d(2)

        self.down2 = DoubleConv(16, 32)
        self.pool2 = nn.MaxPool2d(2)

        self.bridge = DoubleConv(32, 64)

        self.up2   = nn.ConvTranspose2d(64, 32, 2, stride=2)
        self.conv2 = DoubleConv(64, 32)

        self.up1   = nn.ConvTranspose2d(32, 16, 2, stride=2)
        self.conv1 = DoubleConv(32, 16)

        self.final = nn.Conv2d(16, 1, 1)

    def forward(self, x):
        c1 = self.down1(x)
        p1 = self.pool1(c1)

        c2 = self.down2(p1)
        p2 = self.pool2(c2)

        b = self.bridge(p2)

        u2 = self.up2(b)
        m2 = torch.cat([u2, c2], dim=1)
        c4 = self.conv2(m2)

        u1 = self.up1(c4)
        m1 = torch.cat([u1, c1], dim=1)
        c5 = self.conv1(m1)

        out = torch.sigmoid(self.final(c5))
        return out


# -------------------------
# Utilities: preprocessing, mask creation, GVI and advice
# -------------------------

def preprocess_image_from_pil(pil_img):
    img = np.array(pil_img.convert("RGB"))
    img = cv2.resize(img, IMAGE_SIZE)
    img = img.astype(np.float32) / 255.0
    return img


def create_mask_from_green(img):
    img_uint8 = (img * 255).astype(np.uint8)
    hsv = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2HSV)

    lower_green = np.array([35, 40, 25], dtype=np.uint8)
    upper_green = np.array([85, 255, 255], dtype=np.uint8)

    mask = cv2.inRange(hsv, lower_green, upper_green)
    kernel = np.ones((3,3), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)

    mask = (mask > 0).astype(np.float32)
    mask = np.expand_dims(mask, axis=-1)
    return mask


def compute_gvi(img, pred_mask_bin):
    veg_pixels = img[pred_mask_bin[:,:,0] == 1]
    if veg_pixels.size == 0:
        return 0.0
    g_channel = veg_pixels[:, 1]
    return float(g_channel.mean())


def irrigation_advice(prop_agri, gvi):
    if prop_agri < 0.05:
        return "ðŸŸ¤ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ù…Ø¹Ø¸Ù…Ù‡Ø§ ØµØ­Ø±Ø§Ø¡ØŒ Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ù„Ø±ÙŠ Ø£Ùˆ Ø§Ù„Ø²Ø±Ø§Ø¹Ø© Ù…Ø­Ø¯ÙˆØ¯Ø©."
    if prop_agri > 0.70:
        return "ðŸŸ¢ Ø§Ù„ØºØ·Ø§Ø¡ Ø§Ù„Ù†Ø¨Ø§ØªÙŠ ÙƒØ«ÙŠÙ ÙˆØµØ­ÙŠ Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…ØŒ Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø±ÙŠ."
    if gvi > 0.55:
        return "ðŸŸ¢ Ø§Ù„ØºØ·Ø§Ø¡ Ø§Ù„Ù†Ø¨Ø§ØªÙŠ ØµØ­ÙŠØŒ ÙŠÙ…ÙƒÙ† ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø±ÙŠ Ù„ØªØ¬Ù†Ø¨ Ù‡Ø¯Ø± Ø§Ù„Ù…ÙŠØ§Ù‡."
    elif gvi > 0.35:
        return "ðŸŸ¡ Ø­Ø§Ù„Ø© Ù…ØªÙˆØ³Ø·Ø©ØŒ ÙŠÙÙ†ØµØ­ Ø¨Ø±ÙŠ Ù…Ù†ØªØ¸Ù… Ø¨ÙƒÙ…ÙŠØ© Ù…Ø¹ØªØ¯Ù„Ø©."
    else:
        return "ðŸ”´ Ø¥Ø¬Ù‡Ø§Ø¯ ÙˆØ§Ø¶Ø­ ÙÙŠ Ø§Ù„Ù†Ø¨Ø§ØªØ§ØªØŒ ÙŠÙÙ†ØµØ­ Ø¨Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø±ÙŠ ÙˆÙØ­Øµ Ø§Ù„ØªØ±Ø¨Ø© ÙˆÙ†ÙˆØ¹ÙŠØ© Ø§Ù„Ù…ÙŠØ§Ù‡."


# -------------------------
# Load model helper (allow either loading from repo or uploading weights)
# -------------------------

def load_model(weights_path=None):
    model = UNet().to(DEVICE)
    if weights_path is not None and os.path.exists(weights_path):
        state = torch.load(weights_path, map_location=DEVICE)
        model.load_state_dict(state)
    return model


# -------------------------
# Prediction helper
# -------------------------

def predict_numpy_image(model, img):
    # img: HxWx3 float32 0..1
    model.eval()
    img_t = torch.tensor(img.transpose(2,0,1), dtype=torch.float32).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        pred = model(img_t)[0].cpu().numpy()
    pred = np.transpose(pred, (1,2,0))
    return pred


def make_overlay(img, pred_mask):
    pred_mask_bin = (pred_mask > 0.5).astype(np.uint8)
    overlay = (img*255).astype(np.uint8).copy()
    overlay[pred_mask_bin[:,:,0] == 1] = (
        overlay[pred_mask_bin[:,:,0] == 1] * 0.4 +
        np.array([0,255,0]) * 0.6
    ).astype(np.uint8)
    return pred_mask, pred_mask_bin, overlay


# -------------------------
# Streamlit UI
# -------------------------

def main():
    st.set_page_config(page_title="Aerial Vegetation Segmentation", layout="wide")
    st.title("ðŸŒ± Aerial Vegetation Segmentation")

    st.sidebar.header("Model / Input")
    weights_option = st.sidebar.radio("Load weights from:", ("Repository (default)", "Upload file"))

    weights_path = "desert_agri_unet_weights.pth"
    uploaded_weights = None
    if weights_option == "Upload file":
        uploaded_weights = st.sidebar.file_uploader("Upload .pth weights file", type=["pth"], accept_multiple_files=False)
        if uploaded_weights is not None:
            # save temporary
            tmp_path = "uploaded_weights.pth"
            with open(tmp_path, "wb") as f:
                f.write(uploaded_weights.getbuffer())
            weights_path = tmp_path

    st.sidebar.markdown("---")
    input_option = st.sidebar.radio("Input image:", ("Upload image", "Use example from repository"))

    uploaded_image = None
    example_images = []
    # find images in ./images or Aerial_Landscapes if present
    for root, dirs, files in os.walk('.'):
        for fn in files:
            if fn.lower().endswith(('.png', '.jpg', '.jpeg')):
                example_images.append(os.path.join(root, fn))
    example_images = sorted(example_images)

    if input_option == "Upload image":
        uploaded_image = st.file_uploader("Upload an aerial image", type=["png","jpg","jpeg"])
    else:
        if len(example_images) > 0:
            choice = st.selectbox("Choose example", example_images)
            uploaded_image = open(choice, "rb")
        else:
            st.info("No example images found in the repository. Upload an image or add sample images to the repo.")

    # Load model
    with st.spinner("Loading model ..."):
        model = load_model(weights_path)

    if uploaded_image is not None:
        # read image
        pil_img = Image.open(uploaded_image)
        img = preprocess_image_from_pil(pil_img)

        st.subheader("Input")
        st.image((img*255).astype(np.uint8), use_column_width=True)

        if st.button("Run prediction"):
            with st.spinner("Predicting..."):
                pred = predict_numpy_image(model, img)
                pred_mask, pred_mask_bin, overlay = make_overlay(img, pred)

                prop_agri = np.sum(pred_mask_bin) / (pred_mask_bin.shape[0]*pred_mask_bin.shape[1])
                gvi = compute_gvi(img, pred_mask_bin)
                advice = irrigation_advice(prop_agri, gvi)

                st.subheader("Results")
                col1, col2, col3 = st.columns(3)
                col1.image((img*255).astype(np.uint8), caption="Original", use_column_width=True)
                col2.image((pred_mask[:,:,0]*255).astype(np.uint8), caption="Predicted mask", clamp=True, use_column_width=True)
                col3.image(overlay, caption="Overlay (green = vegetation)", use_column_width=True)

                st.markdown(f"**Green area ratio:** {prop_agri*100:.2f}%")
                st.markdown(f"**GVI:** {gvi:.3f}")
                st.markdown(f"**Advice:** {advice}")

    st.sidebar.markdown("---")
    st.sidebar.markdown("**Notes:**\n- Put `desert_agri_unet_weights.pth` in repo root or upload it via the sidebar.\n- Run: `streamlit run app.py`\n- Adjust IMAGE_SIZE in this file if you trained with a different size.")


if __name__ == '__main__':
    main()